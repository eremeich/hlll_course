{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ConvolutionalNNs.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eremeich/hlll_course/blob/master/ConvolutionalNNs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1z6Yw1FA15Ug",
        "colab_type": "text"
      },
      "source": [
        "# Convolutional Neural Networks: Step by Step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AR2T7kYxas1C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (5.0, 4.0) # set default size of plots\n",
        "plt.rcParams['image.interpolation'] = 'nearest'\n",
        "plt.rcParams['image.cmap'] = 'gray'\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "np.random.seed(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4tSVq-R2mcX",
        "colab_type": "text"
      },
      "source": [
        "## Zero-Padding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4704cBh2ISY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# GRADED FUNCTION: zero_pad\n",
        "\n",
        "def zero_pad(X, pad):\n",
        "    \"\"\"\n",
        "    Pad with zeros all images of the dataset X. The padding is applied to the height and width of an image.\n",
        "    \n",
        "    Argument:\n",
        "    X -- python numpy array of shape (m, n_H, n_W, n_C) representing a batch of m images\n",
        "    pad -- integer, amount of padding around each image on vertical and horizontal dimensions\n",
        "    \n",
        "    Returns:\n",
        "    X_pad -- padded image of shape (m, n_H + 2*pad, n_W + 2*pad, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    ###  ### \n",
        "    X_pad = np.pad(X, ((0,0),(pad,pad),(pad,pad),(0,0)), 'constant', constant_values = (0,0))\n",
        "    ###  ###\n",
        "    \n",
        "    return X_pad"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nH61LqQ72VVO",
        "colab_type": "code",
        "outputId": "a3caa102-ccec-46de-d0c7-e59e387fe2bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "np.random.seed(1)\n",
        "x = np.random.randn(4, 3, 3, 2)\n",
        "x_pad = zero_pad(x, 2)\n",
        "print (\"x.shape =\", x.shape)\n",
        "print (\"x_pad.shape =\", x_pad.shape)\n",
        "print (\"x[1,1] =\", x[1,1])\n",
        "print (\"x_pad[1,1] =\", x_pad[1,1])\n",
        "\n",
        "fig, axarr = plt.subplots(1, 2)\n",
        "axarr[0].set_title('x')\n",
        "axarr[0].imshow(x[0,:,:,0])\n",
        "axarr[1].set_title('x_pad')\n",
        "axarr[1].imshow(x_pad[0,:,:,0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x.shape = (4, 3, 3, 2)\n",
            "x_pad.shape = (4, 7, 7, 2)\n",
            "x[1,1] = [[ 0.90085595 -0.68372786]\n",
            " [-0.12289023 -0.93576943]\n",
            " [-0.26788808  0.53035547]]\n",
            "x_pad[1,1] = [[0. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f45a5adb6d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUAAAACtCAYAAADBPaZCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f45a5b3f7f0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdK6Q8TZ2riX",
        "colab_type": "text"
      },
      "source": [
        "## Single step of convolution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4RP6G602a6n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# GRADED FUNCTION: conv_single_step\n",
        "\n",
        "def conv_single_step(a_slice_prev, W, b):\n",
        "    \"\"\"\n",
        "    Apply one filter defined by parameters W on a single slice (a_slice_prev) of the output activation \n",
        "    of the previous layer.\n",
        "    \n",
        "    Arguments:\n",
        "    a_slice_prev -- slice of input data of shape (f, f, n_C_prev)\n",
        "    W -- Weight parameters contained in a window - matrix of shape (f, f, n_C_prev)\n",
        "    b -- Bias parameters contained in a window - matrix of shape (1, 1, 1)\n",
        "    \n",
        "    Returns:\n",
        "    Z -- a scalar value, result of convolving the sliding window (W, b) on a slice x of the input data\n",
        "    \"\"\"\n",
        "\n",
        "    ###  ###\n",
        "    # Element-wise product between a_slice and W. Do not add the bias yet.\n",
        "    s = a_slice_prev * W\n",
        "    # Sum over all entries of the volume s.\n",
        "    Z = np.sum(s)\n",
        "    # Add bias b to Z. Cast b to a float() so that Z results in a scalar value.\n",
        "    Z = float(Z + b)\n",
        "    ###  ###\n",
        "\n",
        "    return Z"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSprNtQx23SU",
        "colab_type": "code",
        "outputId": "edca6db8-b8cf-4656-9874-c5acf67233f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.random.seed(1)\n",
        "a_slice_prev = np.random.randn(4, 4, 3)\n",
        "W = np.random.randn(4, 4, 3)\n",
        "b = np.random.randn(1, 1, 1)\n",
        "\n",
        "Z = conv_single_step(a_slice_prev, W, b)\n",
        "print(\"Z =\", Z)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Z = -6.999089450680221\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lcwp3b-Q3C5J",
        "colab_type": "text"
      },
      "source": [
        "## Convolutional Neural Networks - Forward pass"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNKtNr1W27mS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# GRADED FUNCTION: conv_forward\n",
        "\n",
        "def conv_forward(A_prev, W, b, hparameters):\n",
        "    \"\"\"\n",
        "    Implements the forward propagation for a convolution function\n",
        "    \n",
        "    Arguments:\n",
        "    A_prev -- output activations of the previous layer, numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    W -- Weights, numpy array of shape (f, f, n_C_prev, n_C)\n",
        "    b -- Biases, numpy array of shape (1, 1, 1, n_C)\n",
        "    hparameters -- python dictionary containing \"stride\" and \"pad\"\n",
        "        \n",
        "    Returns:\n",
        "    Z -- conv output, numpy array of shape (m, n_H, n_W, n_C)\n",
        "    cache -- cache of values needed for the conv_backward() function\n",
        "    \"\"\"\n",
        "    \n",
        "    ###  ###\n",
        "    # Retrieve dimensions from A_prev's shape  \n",
        "    (m, n_H_prev, n_W_prev, n_C_prev) = np.shape(A_prev)\n",
        "    \n",
        "    # Retrieve dimensions from W's shape\n",
        "    (f, f, n_C_prev, n_C) = np.shape(W)\n",
        "    \n",
        "    # Retrieve information from \"hparameters\"\n",
        "    stride = hparameters['stride']\n",
        "    pad = hparameters['pad']\n",
        "    \n",
        "    # Compute the dimensions of the CONV output volume.\n",
        "    n_H = int((n_H_prev - f + 2 * pad) / stride) + 1\n",
        "    n_W = int((n_W_prev - f + 2 * pad) / stride) + 1\n",
        "    \n",
        "    # Initialize the output volume Z with zeros.\n",
        "    Z = np.zeros((m, n_H, n_W, n_C))\n",
        "    \n",
        "    # Create A_prev_pad by padding A_prev\n",
        "    A_prev_pad = zero_pad(A_prev, pad)\n",
        "    \n",
        "    for i in range(m):                               # loop over the batch of training examples\n",
        "        a_prev_pad = A_prev_pad[i,:,:,:]               # Select ith training example's padded activation\n",
        "        for h in range(n_H):                           # loop over vertical axis of the output volume\n",
        "            for w in range(n_W):                       # loop over horizontal axis of the output volume\n",
        "                for c in range(n_C):                   # loop over channels (= #filters) of the output volume\n",
        "                    \n",
        "                    # Find the corners of the current \"slice\"\n",
        "                    vert_start = h * stride\n",
        "                    vert_end = h * stride+ f\n",
        "                    horiz_start = w * stride\n",
        "                    horiz_end = w * stride + f\n",
        "                    \n",
        "                    # Use the corners to define the (3D) slice of a_prev_pad.\n",
        "                    a_slice_prev = a_prev_pad[vert_start:vert_end,horiz_start:horiz_end,:]\n",
        "                    \n",
        "                    # Convolve the (3D) slice with the correct filter W and bias b, to get back one output neuron.\n",
        "                    Z[i, h, w, c] = conv_single_step(a_slice_prev,W[:,:,:,c], b[:,:,:,c])\n",
        "                                        \n",
        "    ###  ###\n",
        "    \n",
        "    # Making sure your output shape is correct\n",
        "    assert(Z.shape == (m, n_H, n_W, n_C))\n",
        "    \n",
        "    # Save information in \"cache\" for the backprop\n",
        "    cache = (A_prev, W, b, hparameters)\n",
        "    \n",
        "    return Z, cache"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sa7byOZF3Mgn",
        "colab_type": "code",
        "outputId": "35532ccf-181d-4ab2-b369-031bed1a622e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "np.random.seed(1)\n",
        "A_prev = np.random.randn(10,4,4,3)\n",
        "W = np.random.randn(2,2,3,8)\n",
        "b = np.random.randn(1,1,1,8)\n",
        "hparameters = {\"pad\" : 2,\n",
        "               \"stride\": 2}\n",
        "\n",
        "Z, cache_conv = conv_forward(A_prev, W, b, hparameters)\n",
        "print(\"Z's mean =\", np.mean(Z))\n",
        "print(\"Z[3,2,1] =\", Z[3,2,1])\n",
        "print(\"cache_conv[0][1][2][3] =\", cache_conv[0][1][2][3])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Z's mean = 0.048995203528855794\n",
            "Z[3,2,1] = [-0.61490741 -6.7439236  -2.55153897  1.75698377  3.56208902  0.53036437\n",
            "  5.18531798  8.75898442]\n",
            "cache_conv[0][1][2][3] = [-0.20075807  0.18656139  0.41005165]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVUDSIfn3XX8",
        "colab_type": "text"
      },
      "source": [
        "## Pooling layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBGI5HdW3Ros",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# GRADED FUNCTION: pool_forward\n",
        "\n",
        "def pool_forward(A_prev, hparameters, mode = \"max\"):\n",
        "    \"\"\"\n",
        "    Implements the forward pass of the pooling layer\n",
        "    \n",
        "    Arguments:\n",
        "    A_prev -- Input data, numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    hparameters -- python dictionary containing \"f\" and \"stride\"\n",
        "    mode -- the pooling mode you would like to use, defined as a string (\"max\" or \"average\")\n",
        "    \n",
        "    Returns:\n",
        "    A -- output of the pool layer, a numpy array of shape (m, n_H, n_W, n_C)\n",
        "    cache -- cache used in the backward pass of the pooling layer, contains the input and hparameters \n",
        "    \"\"\"\n",
        "    \n",
        "    # Retrieve dimensions from the input shape\n",
        "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
        "    \n",
        "    # Retrieve hyperparameters from \"hparameters\"\n",
        "    f = hparameters[\"f\"]\n",
        "    stride = hparameters[\"stride\"]\n",
        "    \n",
        "    # Define the dimensions of the output\n",
        "    n_H = int(1 + (n_H_prev - f) / stride)\n",
        "    n_W = int(1 + (n_W_prev - f) / stride)\n",
        "    n_C = n_C_prev\n",
        "    \n",
        "    # Initialize output matrix A\n",
        "    A = np.zeros((m, n_H, n_W, n_C))              \n",
        "    \n",
        "    ###  ###\n",
        "    for i in range(m):                         # loop over the training examples\n",
        "        for h in range(n_H):                     # loop on the vertical axis of the output volume\n",
        "            for w in range(n_W):                 # loop on the horizontal axis of the output volume\n",
        "                for c in range (n_C):            # loop over the channels of the output volume\n",
        "                    \n",
        "                    # Find the corners of the current \"slice\"\n",
        "                    vert_start = h * stride\n",
        "                    vert_end = h * stride + f\n",
        "                    horiz_start = w * stride\n",
        "                    horiz_end = w * stride + f\n",
        "                    \n",
        "                    # Use the corners to define the current slice on the ith training example of A_prev, channel c.\n",
        "                    a_prev_slice = A_prev[i, vert_start:vert_end, horiz_start:horiz_end, c]\n",
        "                    \n",
        "                    # Compute the pooling operation on the slice. Use an if statment to differentiate the modes. Use np.max/np.mean.\n",
        "                    if mode == \"max\":\n",
        "                        A[i, h, w, c] = np.max(a_prev_slice)\n",
        "                    elif mode == \"average\":\n",
        "                        A[i, h, w, c] = np.mean(a_prev_slice)\n",
        "    \n",
        "    ###  ###\n",
        "    \n",
        "    # Store the input and hparameters in \"cache\" for pool_backward()\n",
        "    cache = (A_prev, hparameters)\n",
        "    \n",
        "    # Making sure your output shape is correct\n",
        "    assert(A.shape == (m, n_H, n_W, n_C))\n",
        "    \n",
        "    return A, cache"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZTeS5Ct3d_M",
        "colab_type": "code",
        "outputId": "e4eebf93-5b72-4546-e223-1e12ac874924",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "np.random.seed(1)\n",
        "A_prev = np.random.randn(2, 4, 4, 3)\n",
        "hparameters = {\"stride\" : 2, \"f\": 3}\n",
        "\n",
        "A, cache = pool_forward(A_prev, hparameters)\n",
        "print(\"mode = max\")\n",
        "print(\"A =\", A)\n",
        "print()\n",
        "A, cache = pool_forward(A_prev, hparameters, mode = \"average\")\n",
        "print(\"mode = average\")\n",
        "print(\"A =\", A)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mode = max\n",
            "A = [[[[1.74481176 0.86540763 1.13376944]]]\n",
            "\n",
            "\n",
            " [[[1.13162939 1.51981682 2.18557541]]]]\n",
            "\n",
            "mode = average\n",
            "A = [[[[ 0.02105773 -0.20328806 -0.40389855]]]\n",
            "\n",
            "\n",
            " [[[-0.22154621  0.51716526  0.48155844]]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfgF8B-D4Ei-",
        "colab_type": "text"
      },
      "source": [
        "## Backpropagation in convolutional neural networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4YQusSI3hp3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv_backward(dZ, cache):\n",
        "    \"\"\"\n",
        "    Implement the backward propagation for a convolution function\n",
        "    \n",
        "    Arguments:\n",
        "    dZ -- gradient of the cost with respect to the output of the conv layer (Z), numpy array of shape (m, n_H, n_W, n_C)\n",
        "    cache -- cache of values needed for the conv_backward(), output of conv_forward()\n",
        "    \n",
        "    Returns:\n",
        "    dA_prev -- gradient of the cost with respect to the input of the conv layer (A_prev),\n",
        "               numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    dW -- gradient of the cost with respect to the weights of the conv layer (W)\n",
        "          numpy array of shape (f, f, n_C_prev, n_C)\n",
        "    db -- gradient of the cost with respect to the biases of the conv layer (b)\n",
        "          numpy array of shape (1, 1, 1, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    ###  ###\n",
        "    # Retrieve information from \"cache\"\n",
        "    (A_prev, W, b, hparameters) = cache\n",
        "    \n",
        "    # Retrieve dimensions from A_prev's shape\n",
        "    (m, n_H_prev, n_W_prev, n_C_prev) = np.shape(A_prev)\n",
        "    \n",
        "    # Retrieve dimensions from W's shape\n",
        "    (f, f, n_C_prev, n_C) = np.shape(W)\n",
        "    \n",
        "    # Retrieve information from \"hparameters\"\n",
        "    stride = hparameters['stride']\n",
        "    pad = hparameters['pad']\n",
        "    \n",
        "    # Retrieve dimensions from dZ's shape\n",
        "    (m, n_H, n_W, n_C) = np.shape(dZ)\n",
        "    \n",
        "    # Initialize dA_prev, dW, db with the correct shapes\n",
        "    dA_prev = np.zeros((m, n_H_prev, n_W_prev, n_C_prev))                            \n",
        "    dW = np.zeros((f, f, n_C_prev, n_C))\n",
        "    db = np.zeros((1, 1, 1, n_C))\n",
        "\n",
        "    # Pad A_prev and dA_prev\n",
        "    A_prev_pad = zero_pad(A_prev, pad)\n",
        "    dA_prev_pad = zero_pad(dA_prev, pad)\n",
        "    \n",
        "    for i in range(m):                       # loop over the training examples\n",
        "        \n",
        "        # select ith training example from A_prev_pad and dA_prev_pad\n",
        "        a_prev_pad = A_prev_pad[i,:,:,:]\n",
        "        da_prev_pad = dA_prev_pad[i,:,:,:]\n",
        "        \n",
        "        for h in range(n_H):                   # loop over vertical axis of the output volume\n",
        "            for w in range(n_W):               # loop over horizontal axis of the output volume\n",
        "                for c in range(n_C):           # loop over the channels of the output volume\n",
        "                    \n",
        "                    # Find the corners of the current \"slice\"\n",
        "                    vert_start = h * stride\n",
        "                    vert_end = h * stride+ f\n",
        "                    horiz_start = w * stride\n",
        "                    horiz_end = w * stride + f\n",
        "                    \n",
        "                    # Use the corners to define the slice from a_prev_pad\n",
        "                    a_slice = a_prev_pad[vert_start:vert_end,horiz_start:horiz_end,:]\n",
        "\n",
        "                    # Update gradients for the window and the filter's parameters using the code formulas given above\n",
        "                    da_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :] += W[:,:,:,c] * dZ[i, h, w, c]\n",
        "                    dW[:,:,:,c] += a_slice * dZ[i, h, w, c]\n",
        "                    db[:,:,:,c] += dZ[i, h, w, c]\n",
        "                    \n",
        "        # Set the ith training example's dA_prev to the unpaded da_prev_pad (Hint: use X[pad:-pad, pad:-pad, :])\n",
        "        dA_prev[i, :, :, :] = da_prev_pad[pad:-pad, pad:-pad, :]\n",
        "    ###  ###\n",
        "    \n",
        "    # Making sure your output shape is correct\n",
        "    assert(dA_prev.shape == (m, n_H_prev, n_W_prev, n_C_prev))\n",
        "    \n",
        "    return dA_prev, dW, db"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oypYqGfD4M0v",
        "colab_type": "code",
        "outputId": "138c377c-8819-4032-f36b-9c4c0dc80f5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "np.random.seed(1)\n",
        "dA, dW, db = conv_backward(Z, cache_conv)\n",
        "print(\"dA_mean =\", np.mean(dA))\n",
        "print(\"dW_mean =\", np.mean(dW))\n",
        "print(\"db_mean =\", np.mean(db))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dA_mean = 1.4524377775388075\n",
            "dW_mean = 1.7269914583139097\n",
            "db_mean = 7.839232564616838\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nifBZtJb4XeK",
        "colab_type": "text"
      },
      "source": [
        "## Pooling layer - backward pass\n",
        "\n",
        "### Max pooling - backward passÂ¶\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvhaPYXH4QLP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_mask_from_window(x):\n",
        "    \"\"\"\n",
        "    Creates a mask from an input matrix x, to identify the max entry of x.\n",
        "    \n",
        "    Arguments:\n",
        "    x -- Array of shape (f, f)\n",
        "    \n",
        "    Returns:\n",
        "    mask -- Array of the same shape as window, contains a True at the position corresponding to the max entry of x.\n",
        "    \"\"\"\n",
        "    \n",
        "    ###  ###\n",
        "    mask = (np.max(x) == x)\n",
        "    ###  ###\n",
        "    \n",
        "    return mask"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2cRqFZx4d8o",
        "colab_type": "code",
        "outputId": "5fac1bab-dc56-41c5-981e-6eccfd720b59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "np.random.seed(1)\n",
        "x = np.random.randn(2,3)\n",
        "mask = create_mask_from_window(x)\n",
        "print('x = ', x)\n",
        "print(\"mask = \", mask)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x =  [[ 1.62434536 -0.61175641 -0.52817175]\n",
            " [-1.07296862  0.86540763 -2.3015387 ]]\n",
            "mask =  [[ True False False]\n",
            " [False False False]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tObLgQSS4uIv",
        "colab_type": "text"
      },
      "source": [
        "### Average pooling - backward pass"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKZcTFkl4hbq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def distribute_value(dz, shape):\n",
        "    \"\"\"\n",
        "    Distributes the input value in the matrix of dimension shape\n",
        "    \n",
        "    Arguments:\n",
        "    dz -- input scalar\n",
        "    shape -- the shape (n_H, n_W) of the output matrix for which we want to distribute the value of dz\n",
        "    \n",
        "    Returns:\n",
        "    a -- Array of size (n_H, n_W) for which we distributed the value of dz\n",
        "    \"\"\"\n",
        "    \n",
        "    ###  ###\n",
        "    # Retrieve dimensions from shape\n",
        "    (n_H, n_W) = shape\n",
        "    \n",
        "    # Compute the value to distribute on the matrix\n",
        "    average = dz / (n_H * n_W)\n",
        "    \n",
        "    # Create a matrix where every entry is the \"average\" value\n",
        "    a = np.ones(shape) * average\n",
        "    ###  ###\n",
        "    \n",
        "    return a"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5K3LvadC449C",
        "colab_type": "code",
        "outputId": "c8b99639-83da-40fe-f487-3866efa71b24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "a = distribute_value(2, (2,2))\n",
        "print('distributed value =', a)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "distributed value = [[0.5 0.5]\n",
            " [0.5 0.5]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVSEns7h5Bb0",
        "colab_type": "text"
      },
      "source": [
        "### Putting it together: Pooling backward"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMH6bJSm48zS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pool_backward(dA, cache, mode = \"max\"):\n",
        "    \"\"\"\n",
        "    Implements the backward pass of the pooling layer\n",
        "    \n",
        "    Arguments:\n",
        "    dA -- gradient of cost with respect to the output of the pooling layer, same shape as A\n",
        "    cache -- cache output from the forward pass of the pooling layer, contains the layer's input and hparameters \n",
        "    mode -- the pooling mode you would like to use, defined as a string (\"max\" or \"average\")\n",
        "    \n",
        "    Returns:\n",
        "    dA_prev -- gradient of cost with respect to the input of the pooling layer, same shape as A_prev\n",
        "    \"\"\"\n",
        "    \n",
        "    ###  ###\n",
        "    \n",
        "    # Retrieve information from cache\n",
        "    (A_prev, hparameters) = cache\n",
        "    \n",
        "    # Retrieve hyperparameters from \"hparameters\"\n",
        "    stride = hparameters['stride']\n",
        "    f = hparameters['f']\n",
        "    \n",
        "    # Retrieve dimensions from A_prev's shape and dA's shape\n",
        "    m, n_H_prev, n_W_prev, n_C_prev = A_prev.shape\n",
        "    m, n_H, n_W, n_C = dA.shape\n",
        "    \n",
        "    # Initialize dA_prev with zeros\n",
        "    dA_prev = np.zeros((m, n_H_prev, n_W_prev, n_C_prev))\n",
        "    \n",
        "    for i in range(m):                       # loop over the training examples\n",
        "        \n",
        "        # select training example from A_prev\n",
        "        a_prev = A_prev[i,:,:,:]\n",
        "        \n",
        "        for h in range(n_H):                   # loop on the vertical axis\n",
        "            for w in range(n_W):               # loop on the horizontal axis\n",
        "                for c in range(n_C):           # loop over the channels (depth)\n",
        "                    \n",
        "                    # Find the corners of the current \"slice\"\n",
        "                    vert_start = h * stride\n",
        "                    vert_end = h * stride+ f\n",
        "                    horiz_start = w * stride\n",
        "                    horiz_end = w * stride + f\n",
        "                    \n",
        "                    # Compute the backward propagation in both modes.\n",
        "                    if mode == \"max\":\n",
        "                        \n",
        "                        # Use the corners and \"c\" to define the current slice from a_prev\n",
        "                        a_prev_slice = a_prev[vert_start:vert_end, horiz_start:horiz_end, c]\n",
        "                        # Create the mask from a_prev_slice\n",
        "                        mask = create_mask_from_window(a_prev_slice)\n",
        "                        # Set dA_prev to be dA_prev + (the mask multiplied by the correct entry of dA)\n",
        "                        dA_prev[i, vert_start: vert_end, horiz_start: horiz_end, c] += mask * dA[i, h, w, c]\n",
        "                        \n",
        "                    elif mode == \"average\":\n",
        "                        \n",
        "                        # Get the value a from dA\n",
        "                        da = dA[i, h, w, c]\n",
        "                        # Define the shape of the filter as fxf\n",
        "                        shape = (f, f)\n",
        "                        # Distribute it to get the correct slice of dA_prev. i.e. Add the distributed value of da.\n",
        "                        dA_prev[i, vert_start: vert_end, horiz_start: horiz_end, c] += distribute_value(da, shape)\n",
        "                        \n",
        "    ###  ###\n",
        "    \n",
        "    # Making sure your output shape is correct\n",
        "    assert(dA_prev.shape == A_prev.shape)\n",
        "    \n",
        "    return dA_prev"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acMo4O9S5IoB",
        "colab_type": "code",
        "outputId": "35400ce2-9320-4f9e-9f55-ebf2b45cd9b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "np.random.seed(1)\n",
        "A_prev = np.random.randn(5, 5, 3, 2)\n",
        "hparameters = {\"stride\" : 1, \"f\": 2}\n",
        "A, cache = pool_forward(A_prev, hparameters)\n",
        "dA = np.random.randn(5, 4, 2, 2)\n",
        "\n",
        "dA_prev = pool_backward(dA, cache, mode = \"max\")\n",
        "print(\"mode = max\")\n",
        "print('mean of dA = ', np.mean(dA))\n",
        "print('dA_prev[1,1] = ', dA_prev[1,1])  \n",
        "print()\n",
        "dA_prev = pool_backward(dA, cache, mode = \"average\")\n",
        "print(\"mode = average\")\n",
        "print('mean of dA = ', np.mean(dA))\n",
        "print('dA_prev[1,1] = ', dA_prev[1,1]) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mode = max\n",
            "mean of dA =  0.14571390272918056\n",
            "dA_prev[1,1] =  [[ 0.          0.        ]\n",
            " [ 5.05844394 -1.68282702]\n",
            " [ 0.          0.        ]]\n",
            "\n",
            "mode = average\n",
            "mean of dA =  0.14571390272918056\n",
            "dA_prev[1,1] =  [[ 0.08485462  0.2787552 ]\n",
            " [ 1.26461098 -0.25749373]\n",
            " [ 1.17975636 -0.53624893]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRChzDI35MDI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}